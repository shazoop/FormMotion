{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.draw import random_shapes\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTransforms = 15\n",
    "trainSteps = 1000\n",
    "batchSize = 30 #training \n",
    "sparsePen = 1\n",
    "derivPen = .5\n",
    "epsilon = .0001 #variance of normal density in the smoothed bump function. since argument is r^2, want (.01)^2\n",
    "eta = .01 #learning rate of phi, the dictionary of transforms\n",
    "eta2 = .05 #learning rate of beta, the transform coeff\n",
    "eta3 = .1 #Learning rate of center\n",
    "eta4 = .1 #Learning rate of radii\n",
    "numInference = 50 #arbitrary\n",
    "betaStep = 15 #FOR TRAINED TRANSFORMS. mini cycle for beta\n",
    "attStep = 10 #FOR TRAINED TRANSFORMS. mini cycle for center/radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rationale: since movies of multiple objects, with overlap, will just be sum of two images with values capped at 255,\n",
    "#want transforms to reflect this ceiling like behavior or else prediction might be bad. \n",
    "#Will use a smooth squashing function, tanh.\n",
    "\n",
    "def squash(x):\n",
    "    y = 1.3*np.tanh(x)\n",
    "    return(y)\n",
    "\n",
    "def squash_deriv(x):\n",
    "    y = 1.3*(1-np.tanh(x)**2)\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training algorithm, image sequences with one shape. No need to infer center/radii yet.\n",
    "def timeDiff(beta):\n",
    "    #assuming beta has shape bkt, where k for trans, t for length, B for number of images (usually batch size)\n",
    "    \n",
    "    Zeroes = np.zeros((beta.shape[0],1,beta.shape[2]))\n",
    "    timeDeriv = np.diff(beta, axis= 1)\n",
    "    X = np.concatenate((Zeroes, timeDeriv), axis=1)\n",
    "    Y = np.concatenate((timeDeriv,Zeroes), axis =1)\n",
    "    Z = -1*np.sign(X)+np.sign(Y)\n",
    "    \n",
    "    return(Z)\n",
    "\n",
    "def inferBeta(Input, Output, phi, sparsePen, derivPen, eta2, numInference):\n",
    "    #Assume data has shape (B, T, n2), where number of images(usually batch size) , T is time, and n2 is n^2 for nxn image\n",
    "    #phi is of shape (i,i',k) where i,i' denote image dim, k denotes transform, T is time, and B is batch\n",
    "    #Input are first T-1 frames. Output are frames 2 to T. Infer i^th frame from previous.\n",
    "    \n",
    "    beta = np.zeros((Input.shape[0],Input.shape[1],phi.shape[2])) #initialize beta at 0. beta is shape btk\n",
    "    \n",
    "    for step in range(numInference):\n",
    "        predictions = np.einsum('btk,ijk,btj -> bti', beta, phi, Input)\n",
    "        dTanh = squash_deriv(predictions)\n",
    "        error = Output - squash(predictions)\n",
    "        dBeta = np.einsum('bti,ijk,btj, btj -> btk', error, phi, dTanh, Input) - sparsePen*np.sign(beta) - derivPen*timeDiff(beta)\n",
    "        beta += eta2*dBeta\n",
    "        \n",
    "    return(beta)\n",
    "    \n",
    "def learnTransform(Input, Output, phi, beta, eta, batchSize, numInference):\n",
    "    \n",
    "    for step in range(numInference):\n",
    "        predictions = np.einsum('btk,ijk,btj -> bti', beta, phi, Input)\n",
    "        error = Output - predictions\n",
    "        dPhi = np.einsum('bti, btj, btk -> ijk', error, Input, beta)\n",
    "        phi += (eta/batchSize)*dPhi\n",
    "    \n",
    "    return(phi)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traning algo, image sequences with one shape.\n",
    "\n",
    "def Training1(dataset, trainSteps, batchSize, sparsePen, derivPen, eta, eta2, numInference, numTransforms):\n",
    "    \n",
    "    #intialize phi\n",
    "    dim = dataset.shape[2]\n",
    "    phi = np.random.rand(dim, dim ,numTransforms)\n",
    "    \n",
    "    #start training\n",
    "    for trial in range(trainSteps):\n",
    "        \n",
    "        data_batch = dataset[np.random.randint(0,dataset.shape[0],batchSize)] #create random batch\n",
    "        Input = data_batch[:,:9,:] #will predict next frame from these\n",
    "        Output = data_batch[:,1:10,:] #the frames to be predicted\n",
    "        \n",
    "        #Find beta, fix, then optimize phi\n",
    "        beta = inferBeta(Input, Output, phi, sparsePen, derivPen, eta2, numInference)\n",
    "        phi = learnTransform(Input, Output, phi, beta, eta, batchSize, numInference)\n",
    "        \n",
    "        #renormalize by capping absolute value to 1\n",
    "        phi = phi/(np.abs(phi).max(axis=(0,1),keepdims=True))\n",
    "        \n",
    "    \n",
    "    return(phi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalMatrix(movie_length, dim, center, radius2, epsilon):\n",
    "    normal_matrix = np.empty((center.shape[2], movie_length, dim,dim)) #shape is ktdd, where k is number of transforms, t is time, d is dim of image\n",
    "    \n",
    "    for k in range(center.shape[2]):\n",
    "        for t in range(movie_length):\n",
    "            for i in range(dim):\n",
    "                for j in range(dim):\n",
    "                    normal_matrix[k,t,i,j] = (1/np.sqrt(2*np.pi*epsilon))*np.exp(-(radius2[t,k]-np.linalg.norm(np.array([i,j])-center[:,t,k])**2)**2/(2*epsilon**2))\n",
    "    \n",
    "    return(normal_matrix)\n",
    "\n",
    "def center_ParDeriv(movie_length, dim, center, radius2, epsilon): #calculates partial deriv for center, where each entry is 2-vector\n",
    "    normal_matrix = np.empty((center.shape[2], movie_length, dim,dim)) #shape is ktdd, where k is number of transforms, t is time, d is dim of image\n",
    "    \n",
    "    for k in range(center.shape[2]):\n",
    "        for t in range(movie_length):\n",
    "            for i in range(dim):\n",
    "                for j in range(dim):\n",
    "                    normal_matrix[k,t,i,j] = (1/np.sqrt(2*np.pi*epsilon))*np.exp(-(radius2[t,k]-np.linalg.norm(np.array([i,j])-center[:,t,k])**2)**2/(2*epsilon**2))\n",
    "    \n",
    "    distance_pd = np.empty((2,center.shape[2], movie_length, dim, dim)) #shape 2ktdd\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            distance_pd[:,k,t,i,j] = 2*(np.array([i,j])-center[:,t,k])\n",
    "            \n",
    "    centerPD = np.multiply(distance_pd, normal_matrix)\n",
    "    return(centerPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localImage(Input2, movie_length, dim, center, radius2, epsilon):\n",
    "    local_matrix = np.empty((center.shape[2], movie_length, dim,dim)) #shape is ktdd, where k is number of transforms, t is time, d is dim of image\n",
    "    \n",
    "    for k in range(center.shape[2]):\n",
    "        for t in range(movie_length):\n",
    "            for i in range(dim):\n",
    "                for j in range(dim):\n",
    "                    local_matrix[k,t,i,j] = (np.linalg.norm(np.array([i,j])-center[:,t,k])**2)/radius2[t,k]\n",
    "    local_matrix[local_matrix <= 1+ epsilon] = 1\n",
    "    local_matrix[local_matrix > 1 + epsilon] = 0\n",
    "    \n",
    "    LocalInput2 = np.multiply(local_matrix, Input2)\n",
    "    \n",
    "    return(LocalInput2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InferRadius2(Input2, center, Output, radius2, phi, beta, eta3, epsilon, attStep):\n",
    "    \n",
    "    for step in range(attStep):\n",
    "    \n",
    "        localimg = localImage(Input2, movie_length, dim, center, radius2, epsilon).reshape((center.shape[2],movie_length, Input.shape[1])) #calculate localized images and reshape\n",
    "        \n",
    "        predictions = np.einsum('tk,ijk,ktj -> ti', beta, phi, localimg)\n",
    "        error = Output - squash(predictions)\n",
    "        dTanh = squash_deriv(predictions)\n",
    "        ParDeriv = np.multiply(normalMatrix(movie_length, dim, center, radius2, epsilon), Input2).reshape((center.shape[2],movie_length, Input.shape[1]))\n",
    "        #ParDeriv: each entry of matrix, reshaped as vector, is derivative of localized image wrt radius2\n",
    "        dR = np.einsum('ti, tk, ijk, tj, ktj -> tk', error, beta, phi, dTanh, ParDeriv)\n",
    "        radius2 += eta3*dR\n",
    "                                                                                                                      \n",
    "                                                                                                                \n",
    "    return(radius2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InferCenter(Input2, center, Output, radius2, phi, beta, eta4, epsilon):\n",
    "    \n",
    "    for step in range(attStep):\n",
    "    \n",
    "        localimg = localImage(Input2, movie_length, dim, center, radius2, epsilon).reshape((center.shape[2],movie_length, Input.shape[1])) #calculate localized images and reshape\n",
    "        \n",
    "        predictions = np.einsum('tk,ijk,ktj -> ti', beta, phi, localimg)\n",
    "        error = Output - squash(predictions)\n",
    "        dTanh = squash_deriv(predictions)\n",
    "        centerPD = center_ParDeriv(movie_length, dim, center, radius2, epsilon).reshape((2,center.shape[2],movie_length, Input.shape[1]))\n",
    "        #ParDeriv: each entry of matrix, reshaped as vector, is derivative of localized image wrt radius2\n",
    "        dC = np.einsum('ti, tk, ijk, cktj -> ctk', error, beta, phi, centerPD)\n",
    "        center += eta4*dC\n",
    "                                                                                                                      \n",
    "                                                                                                                \n",
    "    return(center)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InferBeta2(Input2, center, Output, radius2, phi ,beta, eta, epsilon, betaStep):\n",
    "    \n",
    "    for step in range(betaStep):\n",
    "        \n",
    "        localimg = localImage(Input2, movie_length, dim, center, radius2, epsilon).reshape((center.shape[2],movie_length, Input.shape[1])) #calculate localized images and reshape\n",
    "        \n",
    "        predictions = np.einsum('tk,ijk,ktj -> ti', beta, phi, localimg)\n",
    "        error = Output - squash(predictions)\n",
    "        dTanh = squash_deriv(predictions)\n",
    "        dBeta = np.einsum('ti,ijk, tj, ktj -> tk', error, phi, dTanh, localimg) - sparsePen*np.sign(np.expand_dims(beta,axis=0))[0,:,:] - derivPen*timeDiff(np.expand_dims(beta,axis=0))[0,:,:]\n",
    "        #just a bit of reshaping magic above to make the functions work, since sparse/derivPen made for data with extra batch dim\n",
    "        beta += eta2*dBeta\n",
    "    \n",
    "    return(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InferLocal(movie_seq, phi, sparsePen, derivPen, eta2, eta3, eta4, betaStep, attStep, numInference): \n",
    "    #now want to infer beta, center, and radii for a single movie sequence\n",
    "    #***RADII ARE SQUARED, to make computing the derivative easier***\n",
    "    #assume movie sequence is shape txn2, where t is length (movie_length) and n2 is product of dimensions of 2d image\n",
    "    \n",
    "\n",
    "    dim = np.sqrt(movie_seq.shape[1])\n",
    "    Input = movie_seq[:(movie_seq.shape[0]-1)]\n",
    "    Output = movie_seq[1:]\n",
    "    Input2 = Input.reshape((Input.shape[0],dim,dim)) #just reshape to make region of interest indices more natural\n",
    "    numInference2 = 10 #this is arbitrary. want to update each of beta, c, r a little\n",
    "    movie_length = Input2.shape[0]\n",
    "    \n",
    "    beta = np.zeros((Input2.shape[0],phi.shape[2])) #initialize beta at 0. beta is shape tk. movie_seq first dim is t\n",
    "    center = (dim/2)*np.ones((2,movie_length,phi.shape[2])) #shape 2tk (2 since center is 2-vector). initialize centers at center of image. each center is 2-vector\n",
    "    radius2 = (17**2)*np.ones((movie_length,phi.shape[2])) # shape tk.initialize radius2 at 17^2, so start off region of interest as entire image\n",
    "    \n",
    "    for bigStep in range(numInference):\n",
    "        beta = InferBeta2(Input2, center, Output, radius2, phi ,beta, eta, epsilon, betaStep)\n",
    "        radius2 = InferRadius2(Input2, center, Output, radius2, phi, beta, eta3, epsilon, attStep)\n",
    "        center = InferCenter(Input2, center, Output, radius2, phi, beta, eta4, epsilon)\n",
    "    \n",
    "    finalImg = localImage(Input2, movie_length, dim, center, radius2, epsilon).reshape((center.shape[2],movie_length, Input.shape[1]))\n",
    "    final_predictions = np.einsum('tk,ijk,ktj -> ti', beta, phi, finalImg)\n",
    "    \n",
    "    fig = plt.figure(figsize = (20,6)) #plot the figures, top is ground truth, bottom is predictions\n",
    "        for i in range(movie_length):\n",
    "            for j in range(2):\n",
    "                fig.add_subplot(2,movie_length,movie_length*j+i+1)\n",
    "                if j == 0:\n",
    "                    plt.imshow(Output[i].reshape((32,32)),cmap = \"Greys\")\n",
    "                else: \n",
    "                    plt.imshow(final_predictions[i].reshape((32,32)),cmap=\"Greys\")\n",
    "\n",
    "    return((beta,radius2,center))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
