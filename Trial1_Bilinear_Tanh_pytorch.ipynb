{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.draw import random_shapes\n",
    "import cv2\n",
    "import random\n",
    "import torch.nn.functional as f\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate a dimxdim image of a random shape of a size between given bounds\n",
    "def shape_gen(dim, minimum,maximum):\n",
    "    x = random_shapes((dim, dim), max_shapes=1, multichannel=False, intensity_range=(0,0),min_size = minimum, max_size=maximum)[0]\n",
    "    x = (-1*x+255)/255\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgDim = 16 #image dimension\n",
    "mov_length = 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create array of start images\n",
    "images_seq = [shape_gen(imgDim,4,10) for i in range(100000)]\n",
    "images_seq = np.array(images_seq)\n",
    "images_seq = np.expand_dims(images_seq,1)\n",
    "\n",
    "test_seq = [shape_gen(imgDim,4,10) for i in range(1000)]\n",
    "test_seq = np.array(test_seq)\n",
    "test_seq = np.expand_dims(test_seq,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a given collection of start images with (n,1,k,k), with n images of dimension k by k. Trans_range is one-sided,\n",
    "#so trans_range = 4 allows translations of 4 up or down, 4 left or right. same for rot_center, how much the center of \n",
    "#rotation can shift to one-side both up/down. rot_angle is maximum angle in DEGREES\n",
    "def rand_trans(data, trans_range, rot_center, rot_angle): \n",
    "    n, row, col = data[:,0,:,:].shape\n",
    "    Index = [random.randint(0,1) for i in range(n)] #randomly choose either translation or rotation\n",
    "    \n",
    "    def M_gen(i):\n",
    "        if i == 0:\n",
    "            hor = random.randint(-trans_range, trans_range)\n",
    "            ver = random.randint(-trans_range, trans_range)\n",
    "            x = np.float32([[1,0,hor],[0,1,ver]]) #create translation matrix\n",
    "        else:\n",
    "            center = (row/2+random.randint(-rot_center,rot_center),col/2+random.randint(-rot_center,rot_center))\n",
    "            angle = random.uniform(-rot_angle,rot_angle)\n",
    "            x = cv2.getRotationMatrix2D(center,angle,1) #create rotation matrix\n",
    "        return(x)\n",
    "    \n",
    "    Z = np.array([M_gen(i) for i in Index])\n",
    "    \n",
    "    return(Z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = rand_trans(images_seq, 2, 2, 45)\n",
    "M2 = rand_trans(test_seq, 2, 2, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for a given collection of start images - \"data\" - and their associated transformations -\"transform\", one for each start image-\n",
    "#will generate a movie sequence of the desired length. note \"data\" should be np.array of shape (n,1,k,k).\n",
    "def image_gen(data, transform, movie_len,imgDim):\n",
    "    X = data\n",
    "    for j in range(movie_len-1):\n",
    "        Y = np.array([cv2.warpAffine(X[i,j],transform[i],(imgDim,imgDim)) for i in range(data.shape[0])])\n",
    "        Y = np.expand_dims(Y,1) #add the second axis, which denotes time, to concatenate the images\n",
    "        X = np.concatenate((X,Y),axis=1)\n",
    "    \n",
    "    X = X.reshape(X.shape[0],X.shape[1],X.shape[2]**2)\n",
    "    return(X) #reshape so it's easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNP = image_gen(images_seq, M, mov_length, imgDim)\n",
    "test_rawNP = image_gen(test_seq, M2, mov_length, imgDim)\n",
    "\n",
    "data = torch.from_numpy(image_gen(images_seq, M, mov_length, imgDim)).cuda()\n",
    "data = data.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_gen(test_seq, testSize, maxShapes):\n",
    "    \n",
    "    #Set up first array, then just loop by concatenating.\n",
    "    \n",
    "    test_data = test_seq[np.random.randint(0,test_seq.shape[0],maxShapes)] #choose random number of movie sequences\n",
    "    test_data = np.sum(test_data,axis= 0) #sum them together\n",
    "    test_data[test_data > 1] = 1 #cap images at 1\n",
    "    test_data = np.expand_dims(test_data, axis = 0) #add back the extra first axis, which indexes every movie sequence\n",
    "    \n",
    "    for datum in range(1,testSize):\n",
    "        subset = test_seq[np.random.randint(0,test_seq.shape[0],maxShapes)]\n",
    "        subset = np.sum(subset,axis=0)\n",
    "        subset[subset > 1] = 1\n",
    "        subset = np.expand_dims(subset, axis = 0)\n",
    "        test_data = np.concatenate((test_data,subset),axis=0)\n",
    "    \n",
    "    return(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNP = multi_gen(test_rawNP, 100, 2)\n",
    "test = torch.from_numpy(testNP)\n",
    "test = test.float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rationale: since movies of multiple objects, with overlap, will just be sum of two images with values capped at 255,\n",
    "#want transforms to reflect this ceiling like behavior or else prediction might be bad. \n",
    "#Will use a smooth squashing function, tanh.\n",
    "\n",
    "def squash(x):\n",
    "    y = 1.3*torch.tanh(x) #1.3 so will be approxiamtely linear on [-1,1]\n",
    "    return(y)\n",
    "\n",
    "def squash_deriv(x):\n",
    "    y = 1.3*(1-torch.tanh(x)**2)\n",
    "    return(y)\n",
    "\n",
    "def squashNP(x):\n",
    "    y = 1.3*np.tanh(x) #1.3 so will be approxiamtely linear on [-1,1]\n",
    "    return(y)\n",
    "\n",
    "def squash_derivNP(x):\n",
    "    y = 1.3*(1-np.tanh(x)**2)\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTransforms = 16\n",
    "trainSteps = 3000 #1000\n",
    "batchSize = 25 #training \n",
    "sparsePen = 8 #want to half of those in linear model. set to 16/2 = 8\n",
    "derivPen = 8 \n",
    "epsilon = 1 #variance of normal desntiy in the smoothed bump function.\n",
    "eta = .002 #learning rate of phi, the dictionary of transforms\n",
    "eta2 = .002 #learning rate of beta, the transform coeff\n",
    "eta3 = .1 #Learning rate of center\n",
    "eta4 = .2 #Learning rate of radii\n",
    "numInference = 100 #arbitrary, 150\n",
    "numInf2 = 100\n",
    "betaStep = 5 #FOR TRAINED TRANSFORMS. mini cycle for beta\n",
    "attStep = 5 #FOR TRAINED TRANSFORMS. mini cycle for center/radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training algorithm, image sequences with one shape. No need to infer center/radii yet.\n",
    "def timeDeriv(beta):\n",
    "    #assuming beta has shape btk, where k for trans, t for length, B for number of images (usually batch size)\n",
    "    \n",
    "    Zeroes = torch.zeros((beta.size()[0],1,beta.size()[2])).cuda()\n",
    "    timeDiff = beta[:,1:,:] - beta[:,:(beta.size(1)-1),:]\n",
    "    tmDiffnorm = torch.norm(timeDiff, p=1, dim=1)\n",
    "    deriv_part1 = (tmDiffnorm/(tmDiffnorm**2+1)).unsqueeze(1) #normalize across time\n",
    "    X = torch.cat((Zeroes, timeDiff), 1)\n",
    "    Y = torch.cat((timeDiff,Zeroes), 1)\n",
    "    Z = torch.sign(X) - torch.sign(Y)\n",
    "    timeBeta = deriv_part1*Z\n",
    "    \n",
    "    return(timeBeta)\n",
    "\n",
    "def timeDerivNP(beta):\n",
    "    #assuming beta has shape btk, where k for trans, t for length, B for number of images (usually batch size)\n",
    "    \n",
    "    Zeroes = np.zeros((beta.shape[0],1,beta.shape[2]))\n",
    "    timeDiff = np.diff(beta, axis= 1)\n",
    "    tmDiffnorm = np.linalg.norm(timeDiff, ord = 1, axis=1)#normalize across time\n",
    "    deriv_part1 = tmDiffnorm/(tmDiffnorm**2+1) \n",
    "    deriv_part1 = np.expand_dims(deriv_part1, axis = 1)\n",
    "    X = np.concatenate((Zeroes, timeDiff), axis=1)\n",
    "    Y = np.concatenate((timeDiff,Zeroes), axis =1)\n",
    "    Z = np.sign(X)-np.sign(Y)\n",
    "    timeBeta = np.multiply(deriv_part1,Z)\n",
    "    \n",
    "    return(timeBeta)\n",
    "\n",
    "\n",
    "def sparseDeriv(beta):\n",
    "    #assume beta has shape btk.\n",
    "    \n",
    "    norm_beta = torch.norm(beta,p=1, dim=2) #normalize btk, for all batches and time\n",
    "    deriv_part1 = norm_beta/(norm_beta**2+1)\n",
    "    deriv_part1 = deriv_part1.unsqueeze(2)\n",
    "    sparseBeta = deriv_part1*torch.sign(beta)\n",
    "    \n",
    "    return(sparseBeta)\n",
    "\n",
    "def sparseDerivNP(beta):\n",
    "    #assume beta has shape btk.\n",
    "    \n",
    "    norm_beta = np.linalg.norm(beta,ord=1, axis=2) #normalize btk, for all batches and time\n",
    "    deriv_part1 = norm_beta/(norm_beta**2+1)\n",
    "    deriv_part1 = np.expand_dims(deriv_part1, axis = 2)\n",
    "    sparseBeta = np.multiply(deriv_part1,np.sign(beta))\n",
    "    \n",
    "    return(sparseBeta)\n",
    "\n",
    "def inferBeta(Input, Output, phi, sparsePen, derivPen, eta2):\n",
    "    #Assume data has shape (B, T, n2), where number of images(usually batch size) , T is time, and n2 is n^2 for nxn image\n",
    "    #phi is of shape (i,i',k) where i,i' denote image dim, k denotes transform, T is time, and B is batch\n",
    "    #Input are first T-1 frames. Output are frames 2 to T. Infer i^th frame from previous.\n",
    "    \n",
    "    beta1 = torch.rand((Input.size()[0],Input.size()[1],phi.size()[2])).cuda() #initialize beta at 0. beta is shape btk\n",
    "    beta2 = torch.rand((Input.size()[0],Input.size()[1],phi.size()[2])).cuda() #initialize beta at 0. beta is shape btk\n",
    "\n",
    "    for step in range(numInference):\n",
    "        predictions = torch.einsum('btk,ijk, btk, jhk, bth -> bti', beta2, phi, beta1, phi, Input)\n",
    "        pred1 = torch.einsum('btk, ijk, btj -> bti', beta1, phi, Input)\n",
    "        dTanh = squash_deriv(predictions)\n",
    "        error = Output - squash(predictions)\n",
    "        delta = torch.einsum('bti,bti -> bti', error, dTanh)\n",
    "        dBeta2 = torch.einsum('bti,ijk, btj -> btk', delta, phi, pred1) - sparsePen*sparseDeriv(beta1) - derivPen*timeDeriv(beta1)\n",
    "        dBeta1 = torch.einsum('bti, btl, ijl, jhk, bth -> btk', delta, beta2, phi, phi, Input) - sparsePen*sparseDeriv(beta2) - derivPen*timeDeriv(beta2)\n",
    "        beta1 += eta2*dBeta1\n",
    "        beta2 += eta2*dBeta2\n",
    "        \n",
    "    return(beta1, beta2)\n",
    "\n",
    "    \n",
    "def learnTransform(Input, Output, phi, beta1, beta2, eta, batchSize):\n",
    "#     beta1_trunc =  beta1.unsqueeze(3)\n",
    "#     beta1_trunc[:,:,0,0] = 0\n",
    "#     beta2_trunc = beta2.unsqueeze(3)\n",
    "#     beta2_trunc[:,:,0,0] = 0\n",
    "    \n",
    "#     for i in range(1,phi.size()[2]):\n",
    "#         beta1_trunc = torch.cat((beta1_trunc, beta1.unsqueeze(3)), dim =3)\n",
    "#         beta2_trunc = torch.cat((beta2_trunc, beta2.unsqueeze(3)), dim =3)\n",
    "#         beta1_trunc[:,:,i,i] = 0\n",
    "#         beta2_trunc[:,:,i,i] = 0 \n",
    "#     P1 = torch.einsum('bti,bti,btlk, jhl,bth -> ijk', delta, beta1_trunc, phi, Input)\n",
    "#     P2 = torch.einsum('bth,bth,btlk,hik, btj -> ijk', delta, beta2_trunc, phi, Input)\n",
    " \n",
    "    predictions = torch.einsum('btk,ijk, btk, jhk, bth -> bti', beta2, phi, beta1, phi, Input)\n",
    "    offdiag = -1*torch.eye(phi.size()[2])+1\n",
    "    offdiag = offdiag.cuda()\n",
    "    error = Output - squash(predictions)\n",
    "    dTanh = squash_deriv(predictions)\n",
    "    delta = torch.einsum('bti,bti -> bti', error, dTanh)\n",
    "    beta_diag = torch.einsum('btk,btk -> btk', beta1, beta2) #need this to ease memory load\n",
    "\n",
    "    #need intermediate P1_hold, P3_2hold to ease memory load\n",
    "    P1_hold = torch.einsum('kl, btl, jhl, bth -> btjk', offdiag, beta1, phi, Input)\n",
    "    P1 = torch.einsum('bti, btk, btjk -> ijk', delta, beta2, P1_hold)\n",
    "    P2 = torch.einsum('bth, btk, kl, btl, hil, btj -> ijk', delta, beta1, offdiag, beta2, phi, Input)\n",
    "    P3_1 = torch.einsum('bth, btk, hik, btj -> ijk', delta, beta_diag, phi, Input)\n",
    "    P3_2hold = torch.einsum('jhk,bth -> btjk', phi, Input)\n",
    "    P3_2 = torch.einsum('bti, btk, btjk -> ijk', delta, beta_diag, P3_2hold)\n",
    "    phi += (eta/batchSize)*(P1+P2+P3_1+P3_2)\n",
    "    \n",
    "    return(phi, error)\n",
    "    \n",
    "\n",
    "#Traning algo, image sequences with one shape.\n",
    "\n",
    "def TrainMore(dataset, phi, trainSteps, batchSize, sparsePen, derivPen, eta, eta2, numInference, numTransforms):\n",
    "    \n",
    "    #intialize phi\n",
    "    dim = dataset.size()[2]\n",
    "    \n",
    "    #ax = plt.subplot(1,1,1)\n",
    "    #start training\n",
    "    for trial in range(trainSteps):\n",
    "        \n",
    "        data_batch = dataset[np.random.randint(0,dataset.size()[0],batchSize)] #create random batch\n",
    "        Input = data_batch[:,:(dataset.size()[1]-1),:] #will predict next frame from these\n",
    "        Output = data_batch[:,1:,:] #the frames to be predicted\n",
    "\n",
    "        #Find beta, fix, then optimize phi\n",
    "        beta1, beta2 = inferBeta(Input, Output, phi, sparsePen, derivPen, eta2)\n",
    "        phi, error = learnTransform(Input, Output, phi, beta1, beta2, eta, batchSize)\n",
    "\n",
    "        #renormalize by making transforms have norm 1.\n",
    "        #phi = phi/(torch.abs(phi).max(axis=(0,1),keepdims=True))\n",
    "        phi = (f.normalize(phi.view(dim**2,numTransforms),dim=0)).view(dim,dim,numTransforms)\n",
    "\n",
    "\n",
    "        if trial%10 == 0: #print every 10 steps\n",
    "            normError = torch.norm(error).item()\n",
    "            print('trial: %s ; NormedLoss: %s' % (trial,normError))\n",
    "        else:\n",
    "            print('trial: %s' % trial, end='\\r')\n",
    "#             normError = torch.norm(error).item()\n",
    "#             print('trial: %s ; NormedLoss: %s' % (trial,normError))\n",
    "#     plt.show()\n",
    "    return(phi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Use this to check what SparsePen/derivPen should be. For 16x16, 1/60 and 1/90 for Sparse/Deriv respectively seems\n",
    "# #to be a good starting point relative to total batch-wide normedError. Maybe want a little higher\n",
    "\n",
    "# data_batch = data[np.random.randint(0,data.size()[0],batchSize)] #create random batch\n",
    "# Input = data_batch[:,:(data.size()[1]-1),:] #will predict next frame from these\n",
    "# Output = data_batch[:,1:,:] #the frames to be predicted\n",
    "\n",
    "# predictions = torch.einsum('btk,ijk, btk, jhk, bth -> bti', beta2, phi, beta1, phi, Input)\n",
    "# offdiag = -1*torch.eye(phi.size()[2])+1\n",
    "# offdiag = offdiag.cuda()\n",
    "# error = Output - squash(predictions)\n",
    "# dTanh = squash_deriv(predictions)\n",
    "# delta = torch.einsum('bti,bti -> bti', error, dTanh)\n",
    "\n",
    "# dim = data.size()[2]\n",
    "# phi = torch.rand(dim, dim ,numTransforms).cuda()+.0001 #n2 x n2 x 15. added small number to prevent dividing by zero.\n",
    "\n",
    "# P3_2 = torch.einsum('bti, btk, jhk, bth -> ijk', delta, beta_diag, phi, Input)\n",
    "\n",
    "# P2 = torch.einsum('bth, btk, kl, btl, hil, btj -> ijk', delta, beta1, offdiag, beta2, phi, Input)\n",
    "\n",
    "\n",
    "# P3_2hold = torch.einsum('jhk,bth -> btjk', phi, Input)\n",
    "# P3_2 = torch.einsum('bti, btk, btjk -> ijk', delta, beta_diag, P3_2hold)\n",
    "\n",
    "\n",
    "# beta1_trunc =  beta1.unsqueeze(3)\n",
    "# beta1_trunc[:,:,0,0] = 0\n",
    "# beta2_trunc = beta2.unsqueeze(3)\n",
    "# beta2_trunc[:,:,0,0] = 0\n",
    "\n",
    "# for i in range(1,phi.size()[2]):\n",
    "#     beta1_trunc = torch.cat((beta1_trunc, beta1.unsqueeze(3)), dim =3)\n",
    "#     beta2_trunc = torch.cat((beta2_trunc, beta2.unsqueeze(3)), dim =3)\n",
    "#     beta1_trunc[:,:,i,i] = 0\n",
    "#     beta2_trunc[:,:,i,i] = 0 \n",
    "\n",
    "\n",
    "    \n",
    "# #     P1 = torch.einsum('bti,bti,btlk, jhl,bth -> ijk', error, dTanh, beta1_trunc, phi, Input)\n",
    "# #     P2 = torch.einsum('bth,bth,btlk,hik, btj -> ijk', erorr, dTanh, beta2_trunc, phi, Input)\n",
    "# P1 = torch.einsum('bti, btk, kl, btl,jhl,bth -> ijk', delta, beta2, offdiag,beta1, phi, Input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Find beta, fix, then optimize phi\n",
    "# beta = inferBeta(Input, Output, phi, sparsePen, derivPen, eta2)\n",
    "# phi, error = learnTransform(Input, Output, phi, beta, eta, batchSize)\n",
    "\n",
    "# #renormalize by making transforms have norm 1.\n",
    "# #phi = phi/(torch.abs(phi).max(axis=(0,1),keepdims=True))\n",
    "# phi = (f.normalize(phi.view(dim**2,numTransforms),dim=0)).view(dim,dim,numTransforms)\n",
    "\n",
    "# timeDiff = beta[:,1:,:] - beta[:,:(beta.size(1)-1),:]\n",
    "# tmDiffnorm = torch.norm(timeDiff,dim=1)\n",
    "\n",
    "# print('sparse: %s  time: %s  error: %s' % (torch.log(torch.norm(beta)**4 + 1),torch.log(torch.norm(timeDiff)**4 + 1),torch.norm(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traning algo, image sequences with one shape.\n",
    "\n",
    "def Training1(dataset, trainSteps, batchSize, sparsePen, derivPen, eta, eta2, numInference, numTransforms):\n",
    "    \n",
    "    #intialize phi\n",
    "    dim = dataset.size()[2]\n",
    "    phi = torch.rand(dim, dim ,numTransforms).cuda()+.0001 #n2 x n2 x 15. added small number to prevent dividing by zero.\n",
    "    \n",
    "    #ax = plt.subplot(1,1,1)\n",
    "    #start training\n",
    "    eta_phase2 = eta*.5\n",
    "#     sparsePen_phase2 = sparsePen*.8\n",
    "#     derivPen_phase2 = derivPen*.8\n",
    "    for trial in range(trainSteps): #iteratively relax learning rate\n",
    "        if trial <= trainSteps/3:\n",
    "            pass\n",
    "        else:\n",
    "            eta= eta_phase2\n",
    "#             sparsePen = sparsePen_phase2\n",
    "#             derivPen = derivPen_phase2\n",
    "#above code also in case want to intitally force algo to choose sparse, time-consistent soltuions to get good \"initializations\"\n",
    "        \n",
    "        data_batch = dataset[np.random.randint(0,dataset.size()[0],batchSize)] #create random batch\n",
    "        Input = data_batch[:,:(dataset.size()[1]-1),:] #will predict next frame from these\n",
    "        Output = data_batch[:,1:,:] #the frames to be predicted\n",
    "\n",
    "        #Find beta, fix, then optimize phi\n",
    "        beta1, beta2 = inferBeta(Input, Output, phi, sparsePen, derivPen, eta2)\n",
    "        phi, error = learnTransform(Input, Output, phi, beta1, beta2, eta, batchSize)\n",
    "\n",
    "        #renormalize by making transforms have norm 1.\n",
    "        #phi = phi/(torch.abs(phi).max(axis=(0,1),keepdims=True))\n",
    "        phi = (f.normalize(phi.view(dim**2,numTransforms),dim=0)).view(dim,dim,numTransforms)\n",
    "\n",
    "\n",
    "#         if trial%10 == 0: #print every 10 steps\n",
    "#             normError = torch.norm(error).item()\n",
    "#             print('trial: %s ; NormedLoss: %s' % (trial,normError))\n",
    "#         else:\n",
    "#             print('trial: %s' % trial, end='\\r')\n",
    "        normError = torch.norm(error).item()\n",
    "        print('trial: %s ; NormedLoss: %s' % (trial,normError))\n",
    "#     plt.show()\n",
    "    return(phi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: 0 ; NormedLoss: 255.54151916503906\n",
      "trial: 1 ; NormedLoss: 94.2687759399414\n",
      "trial: 2 ; NormedLoss: 72.9780502319336\n",
      "trial: 3 ; NormedLoss: 48.506187438964844\n",
      "trial: 4 ; NormedLoss: 50.687625885009766\n",
      "trial: 5 ; NormedLoss: 38.854434967041016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ae7a5d140554>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearnedPhi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTraining1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainSteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparsePen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderivPen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumInference\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumTransforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-38037116084d>\u001b[0m in \u001b[0;36mTraining1\u001b[1;34m(dataset, trainSteps, batchSize, sparsePen, derivPen, eta, eta2, numInference, numTransforms)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#         else:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m#             print('trial: %s' % trial, end='\\r')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mnormError\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trial: %s ; NormedLoss: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#     plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learnedPhi = Training1(data, trainSteps, batchSize, sparsePen, derivPen, eta, eta2, numInference, numTransforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnedPhi8NP = torch.Tensor.numpy(torch.Tensor.cpu(learnedPhi8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnPhi8NP = np.load(\"Trial2_learnedPhi8.npy\")\n",
    "learnPhi9NP = np.load(\"Trial2_learnedPhi9.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnedPhi8 = torch.from_numpy(learnPhi8NP).cuda()\n",
    "learnedPhi9 = torch.from_numpy(learnPhi9NP).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now test learned Phi on dataset\n",
    "data_batch = data[np.random.randint(0,data.shape[0],batchSize)] #create random batch\n",
    "Input = data_batch[:,:(data.shape[1]-1),:] #will predict next frame from these\n",
    "Output = data_batch[:,1:,:] #the frames to be predicted\n",
    "dim = data.size()[2]\n",
    "beta = inferBeta(Input, Output, learnedPhi8, sparsePen, derivPen, eta2)\n",
    "predictions = torch.einsum('btk,ijk,btj -> bti', beta, learnedPhi8, Input)\n",
    "predictionsNP = torch.Tensor.numpy(torch.Tensor.cpu(predictions))\n",
    "predictionsNP[predictionsNP < 0] = 0\n",
    "OutputNP = torch.Tensor.numpy(torch.Tensor.cpu(Output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare actual to predicted.\n",
    "data_number =17\n",
    "fig = plt.figure(figsize=(20,10)) #image sequence from dataset\n",
    "for i in range(10):\n",
    "    fig.add_subplot(2,5,i+1)\n",
    "    if i <= 4:\n",
    "        plt.imshow(OutputNP[data_number,i].reshape((imgDim,imgDim)),cmap = \"Greys\")\n",
    "    else:\n",
    "        plt.imshow(predictionsNP[data_number,i-5].reshape((imgDim,imgDim)),cmap = \"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = torch.zeros(numTransforms,6,data.size()[2]).cuda()\n",
    "testdata[:,0,:] = data[17,0]\n",
    "for i in range(numTransforms):\n",
    "    for j in range(5):\n",
    "        testdata[i,j+1] = torch.einsum('ij,j -> i', learnedPhi8[:,:,i],testdata[i,j])\n",
    "    \n",
    "testdataNP = torch.Tensor.numpy(torch.Tensor.cpu(testdata))\n",
    "testdataNP = testdataNP.reshape((testdataNP.shape[0],testdataNP.shape[1],imgDim,imgDim))\n",
    "fig = plt.figure(figsize=(20,20)) #image sequence from dataset\n",
    "for i in range(6*numTransforms):\n",
    "        fig.add_subplot(numTransforms,6,i+1)\n",
    "        plt.imshow(testdataNP[i//6,i%6],cmap = \"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = torch.zeros(numTransforms,6,data.size()[2]).cuda()\n",
    "testdata[:,0,:] = data[17,0]\n",
    "for i in range(numTransforms):\n",
    "    for j in range(5):\n",
    "        testdata[i,j+1] = torch.einsum('ij,j -> i', learnedPhi9[:,:,i],testdata[i,j])\n",
    "    \n",
    "testdataNP = torch.Tensor.numpy(torch.Tensor.cpu(testdata))\n",
    "testdataNP = testdataNP.reshape((testdataNP.shape[0],testdataNP.shape[1],imgDim,imgDim))\n",
    "fig = plt.figure(figsize=(20,20)) #image sequence from dataset\n",
    "for i in range(6*numTransforms):\n",
    "        fig.add_subplot(numTransforms,6,i+1)\n",
    "        plt.imshow(testdataNP[i//6,i%6],cmap = \"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action of a single transform on an image. Right frame is action of transform on left frame.\n",
    "phi_index = 7\n",
    "testdata = torch.zeros_like(data[17,0:6])\n",
    "testdata[0] = data[17,0]\n",
    "for i in range(5):\n",
    "    testdata[i+1] = torch.einsum('ij,j -> i', learnedPhi5[:,:,phi_index],testdata[i])\n",
    "    \n",
    "testdataNP = torch.Tensor.numpy(torch.Tensor.cpu(testdata))\n",
    "testdataNP = testdataNP.reshape((testdataNP.shape[0],imgDim,imgDim))\n",
    "fig = plt.figure(figsize=(20,20)) #image sequence from dataset\n",
    "for i in range(6):\n",
    "        fig.add_subplot(1,6,i+1)\n",
    "        plt.imshow(testdataNP[i],cmap = \"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def InferRadius2(localimg, center, Output, radius2, phi, beta, eta3, epsilon, attStep, movie_length):\n",
    "    \n",
    "#     for step in range(attStep):\n",
    "    \n",
    "#         localimg = localImage(Input2, movie_length, dim, center, radius2, epsilon).view((center.size()[2],movie_length, Input2.size()[1]**2)) #calculate localized images and reshape\n",
    "        \n",
    "#         predictions = torch.einsum('tk,ijk,ktj -> ti', beta, phi, localimg)\n",
    "#         error = Output - squash(predictions)\n",
    "#         dTanh = squash_deriv(predictions)\n",
    "#         ParDeriv = normalMatrix(movie_length, dim, center, radius2, epsilon).view(center.size()[2],movie_length, Input2.size()[1]**2)\n",
    "#         #ParDeriv: each entry of matrix, reshaped as vector, is derivative of localized image wrt radius2\n",
    "#         dR = torch.einsum('ti, tk, ijk, tj, ktj -> tk', error, beta, phi, dTanh, ParDeriv)\n",
    "#         radius2 += eta3*dR\n",
    "                                                                                                                      \n",
    "                                                                                                                \n",
    "#     return(radius2)      \n",
    "\n",
    "# def InferCenter(Input2, center, Output, radius2, phi, beta, eta4, epsilon, attStep, movie_length):\n",
    "    \n",
    "#     for step in range(attStep):\n",
    "    \n",
    "#         localimg = localImage(Input2, movie_length, dim, center, radius2, epsilon).view((center.size()[2],movie_length, Input2.size()[1]**2)) #calculate localized images and reshape\n",
    "        \n",
    "#         predictions = torch.einsum('tk,ijk,ktj -> ti', beta, phi, localimg)\n",
    "#         error = Output - squash(predictions)\n",
    "#         dTanh = squash_deriv(predictions)\n",
    "#         centerPD = center_ParDeriv(movie_length, dim, center, radius2, epsilon).view(2,center.size()[2],movie_length, Input2.size()[1]**2)\n",
    "#         #ParDeriv: each entry of matrix, reshaped as vector, is derivative of localized image wrt radius2\n",
    "#         dC = torch.einsum('ti, tk, ijk, tj, cktj -> ctk', error, beta, phi, dTanh, centerPD)\n",
    "#         center += eta4*dC\n",
    "                                                                                                                      \n",
    "                                                                                                                \n",
    "#     return(center)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def InferLocal2(movie_seq, phi, sparsePen, derivPen, eta2, eta3, eta4, betaStep, attStep, numInference): \n",
    "#     #now want to infer beta, center, and radii for a single movie sequence\n",
    "#     #***RADII ARE SQUARED, to make computing the derivative easier***\n",
    "#     #assume movie sequence is shape txn2, where t is length (movie_length) and n2 is product of dimensions of 2d image\n",
    "    \n",
    "#     dim = int(np.sqrt(movie_seq.size()[1]))\n",
    "#     Input = movie_seq[:(movie_seq.size()[0]-1)]\n",
    "#     Output = movie_seq[1:]\n",
    "#     Input2 = Input.view(Input.size()[0],dim,dim) #just reshape to make region of interest indices more natural\n",
    "#     movie_length = Input2.size()[0]\n",
    "    \n",
    "#     beta = torch.zeros(Input2.size()[0],phi.size()[2]) #initialize beta at 0. beta is shape tk. movie_seq first dim is t\n",
    "#     center = (dim/2)*torch.ones(2,movie_length,phi.size()[2]).cuda() #shape 2tk (2 since center is 2-vector). initialize centers at center of image. each center is 2-vector\n",
    "#     radius2 = ((dim/2)**2)*torch.ones(movie_length,phi.size()[2]).cuda() # shape tk.initialize radius2 at r^2, so start off region of interest as entire image\n",
    "    \n",
    "#     for bigStep in range(numInference):\n",
    "#         beta = InferBeta2(Input2, center, Output, radius2, phi ,beta, eta2, epsilon, betaStep, movie_length)\n",
    "#         radius2 = InferRadius2(Input2, center, Output, radius2, phi, beta, eta3, epsilon, attStep, movie_length)\n",
    "#         center = InferCenter(Input2, center, Output, radius2, phi, beta, eta4, epsilon, attStep, movie_length)\n",
    "#         print(bigStep, end='\\r', flush=True)\n",
    "    \n",
    "#     finalImg = localImage(Input2, movie_length, dim, center, radius2, epsilon).view(center.size()[2],movie_length, Input.size()[1])\n",
    "#     final_predictions = torch.einsum('tk,ijk,ktj -> ti', beta, phi, finalImg)\n",
    "#     final_predictionsNP = torch.Tensor.numpy(final_predictions)\n",
    "    \n",
    "#     fig = plt.figure(figsize = (20,6)) #plot the figures, top is ground truth, bottom is predictions\n",
    "#     for i in range(movie_length):\n",
    "#         for j in range(2):\n",
    "#             fig.add_subplot(2,movie_length,movie_length*j+i+1)\n",
    "#             if j == 0:\n",
    "#                 plt.imshow(Output[i].reshape((dim,dim)),cmap = \"Greys\")\n",
    "#             else: \n",
    "#                 plt.imshow(final_predictions[i].reshape((dim,dim)),cmap=\"Greys\")\n",
    "    \n",
    "#     return((beta,radius2,center))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localImage(Input2, movie_length, dim, center, radius2, epsilon):\n",
    "    local_matrix = torch.zeros(center.size()[2], movie_length, dim,dim).cuda() #shape is ktdd, where k is number of transforms, t is time, d is dim of image\n",
    "    \n",
    "    for k in range(center.size()[2]):\n",
    "        for t in range(movie_length):\n",
    "            for i in range(dim):\n",
    "                for j in range(dim):\n",
    "                    local_matrix[k,t,i,j] = (torch.norm(torch.FloatTensor([i,j]).cuda()-center[:,t,k])**2)/radius2[t,k]\n",
    "    local_matrix[local_matrix <= 1+ epsilon] = 1\n",
    "    local_matrix[local_matrix > 1 + epsilon] = 0\n",
    "    \n",
    "    LocalInput2 = local_matrix*Input2\n",
    "    \n",
    "    return(LocalInput2)\n",
    "\n",
    "def InferNbd(Input2, center, Output, radius2, phi, beta, eta3, eta4, epsilon, attStep, movie_length, dim):\n",
    "    for step in range(attStep):\n",
    "        localimg = localImage(Input2, movie_length, dim, center, radius2, epsilon).reshape((center.size()[2],movie_length, Input2.size()[1]**2)) #calculate localized images and reshape\n",
    "        \n",
    "        predictions = torch.einsum('tk,ijk,ktj -> ti', beta, phi, localimg)\n",
    "        error = Output - squash(predictions)\n",
    "        dTanh = squash_deriv(predictions)\n",
    "        normal_matrix = normalMatrix(movie_length,dim,center,radius2,epsilon)\n",
    "        distance_pd = torch.zeros((2,center.size()[2], movie_length, dim, dim)).cuda() #shape 2ktdd\n",
    "    \n",
    "        for k in range(distance_pd.size()[0]):\n",
    "            for t in range(movie_length):\n",
    "                for i in range(dim):\n",
    "                    for j in range(dim):\n",
    "                            distance_pd[:,k,t,i,j] = 2*(torch.FloatTensor([i,j]).cuda()-center[:,t,k])\n",
    "\n",
    "        centerPD = (distance_pd*normal_matrix.unsqueeze(0)).view(2,center.size()[2],movie_length, Input2.size()[1]**2)\n",
    "        ParDeriv = normal_matrix.view(center.size()[2],movie_length, Input2.size()[1]**2) #radius partial deriv\n",
    "        \n",
    "        \n",
    "        dR = torch.einsum('ti, tk, ijk, tj, ktj -> tk', error, beta, phi, dTanh, ParDeriv)\n",
    "        radius2 += eta3*dR\n",
    "        dC = torch.einsum('ti, tk, ijk, tj, cktj -> ctk', error, beta, phi, dTanh, centerPD)\n",
    "        center += eta4*dC\n",
    "    return(radius2,center)\n",
    "\n",
    "def InferBeta2(Input2, center, Output, radius2, phi ,beta, eta, epsilon, nbdStep, movie_length, dim):\n",
    "    \n",
    "    for step in range(betaStep):\n",
    "        \n",
    "        localimg = localImage(Input2, Input2.size()[0], dim, center, radius2, epsilon).view(center.size()[2],movie_length, Input2.size()[1]**2) #calculate localized images and reshape\n",
    "        \n",
    "        \n",
    "        predictions = torch.einsum('tk,ijk,ktj -> ti', beta, phi, localimg)\n",
    "        error = Output - squash(predictions)\n",
    "        dTanh = squash_deriv(predictions)\n",
    "        dBeta = torch.einsum('ti,ijk, tj, ktj -> tk', error, phi, dTanh, localimg) - sparsePen*sparseDeriv(beta.unsqueeze(1))[0,:,:] - derivPen*timeDeriv(beta.unsqueeze(1))[0,:,:]\n",
    "        #just a bit of reshaping magic above to make the functions work, since sparse/derivPen made for data with extra batch dim\n",
    "        beta += eta2*dBeta\n",
    "    \n",
    "    return(beta)\n",
    "\n",
    "def InferLocal(movie_seq, phi, sparsePen, derivPen, eta2, eta3, eta4, betaStep, attStep, numInf2): \n",
    "    #now want to infer beta, center, and radii for a single movie sequence\n",
    "    #***RADII ARE SQUARED, to make computing the derivative easier***\n",
    "    #assume movie sequence is shape txn2, where t is length (movie_length) and n2 is product of dimensions of 2d image\n",
    "    \n",
    "    dim = int(np.sqrt(movie_seq.size()[1]))\n",
    "    Input = movie_seq[:(movie_seq.size()[0]-1)]\n",
    "    Output = movie_seq[1:]\n",
    "    Input2 = Input.view(Input.size()[0],dim,dim) #just reshape to make region of interest indices more natural\n",
    "    movie_length = Input2.size()[0]\n",
    "    \n",
    "    beta = torch.zeros(Input2.size()[0],phi.size()[2]) #initialize beta at 0. beta is shape tk. movie_seq first dim is t\n",
    "    center = (dim/2)*torch.ones(2,movie_length,phi.size()[2]).cuda() #shape 2tk (2 since center is 2-vector). initialize centers at center of image. each center is 2-vector\n",
    "    radius2 = ((dim/2)**2)*torch.ones(movie_length,phi.size()[2]).cuda() # shape tk.initialize radius2 at r^2, so start off region of interest as entire image\n",
    "    \n",
    "    for bigStep in range(numInf2):\n",
    "        beta = InferBeta2(Input2, center, Output, radius2, phi ,beta, eta2, epsilon, betaStep, movie_length, dim)\n",
    "        radius2, center  = InferNbd(Input2, center, Output, radius2, phi, beta, eta3, eta4, epsilon, attStep, movie_length,dim)\n",
    "        print(bigStep, end='\\r', flush=True)\n",
    "    \n",
    "    finalImg = localImage(Input2, movie_length, dim, center, radius2, epsilon).view(center.size()[2],movie_length, Input.size()[1])\n",
    "    final_predictions = torch.einsum('tk,ijk,ktj -> ti', beta, phi, finalImg)\n",
    "    final_predictionsNP = torch.Tensor.numpy(final_predictions)\n",
    "    \n",
    "    fig = plt.figure(figsize = (20,6)) #plot the figures, top is ground truth, bottom is predictions\n",
    "    for i in range(movie_length):\n",
    "        for j in range(2):\n",
    "            fig.add_subplot(2,movie_length,movie_length*j+i+1)\n",
    "            if j == 0:\n",
    "                plt.imshow(Output[i].reshape((dim,dim)),cmap = \"Greys\")\n",
    "            else: \n",
    "                plt.imshow(final_predictions[i].reshape((dim,dim)),cmap=\"Greys\")\n",
    "    \n",
    "    return((beta,radius2,center))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testrun = InferLocal(test[0], learnedPhi8, sparsePen, derivPen, eta2, eta3, eta4, betaStep, attStep, numInf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def InferRadius2NP(Input2, center, Output, radius2, phi, beta, eta3, epsilon, attStep, movie_length, dim):\n",
    "    \n",
    "#     for step in range(attStep):\n",
    "    \n",
    "#         localimg = localImage(Input2, movie_length, dim, center, radius2, epsilon).reshape((center.shape[2],movie_length, Input2.shape[1]**2)) #calculate localized images and reshape\n",
    "        \n",
    "#         predictions = np.einsum('tk,ijk,ktj -> ti', beta, phi, localimg, optimize=True)\n",
    "#         error = Output - squashNP(predictions)\n",
    "#         dTanh = squash_derivNP(predictions)\n",
    "#         ParDeriv = np.multiply(normalMatrixNP(movie_length, dim, center, radius2, epsilon), Input2).reshape((center.shape[2],movie_length, Input2.shape[1]**2))\n",
    "#         #ParDeriv: each entry of matrix, reshaped as vector, is derivative of localized image wrt radius2\n",
    "#         dR = np.einsum('ti, tk, ijk, tj, ktj -> tk', error, beta, phi, dTanh, ParDeriv, optimize=True)\n",
    "#         radius2 += eta3*dR\n",
    "                                                                                                                      \n",
    "                                                                                                                \n",
    "#     return(radius2)      \n",
    "\n",
    "# def InferCenterNP(Input2, center, Output, radius2, phi, beta, eta4, epsilon, attStep, movie_length, dim):\n",
    "    \n",
    "#     for step in range(attStep):\n",
    "    \n",
    "#         localimg = localImage(Input2, movie_length, dim, center, radius2, epsilon).reshape((center.shape[2],movie_length, Input2.shape[1]**2)) #calculate localized images and reshape\n",
    "        \n",
    "#         predictions = np.einsum('tk,ijk,ktj -> ti', beta, phi, localimg, optimize=True)\n",
    "#         error = Output - squashNP(predictions)\n",
    "#         dTanh = squash_derivNP(predictions)\n",
    "#         centerPD = center_ParDeriv(movie_length, dim, center, radius2, epsilon).reshape((2,center.shape[2],movie_length, Input2.shape[1]**2))\n",
    "#         #ParDeriv: each entry of matrix, reshaped as vector, is derivative of localized image wrt radius2\n",
    "#         dC = np.einsum('ti, tk, ijk, cktj -> ctk', error, beta, phi, centerPD, optimize=True)\n",
    "#         center += eta4*dC\n",
    "                                                                                                                      \n",
    "                                                                                                                \n",
    "#     return(center)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim = int(np.sqrt(movie_seq.shape[1]))\n",
    "# Input = movie_seq[:(movie_seq.shape[0]-1)]\n",
    "# Output = movie_seq[1:]\n",
    "# Input2 = Input.reshape((Input.shape[0],dim,dim)) #just reshape to make region of interest indices more natural\n",
    "# movie_length = Input2.shape[0]\n",
    "\n",
    "# beta = np.zeros((Input2.shape[0],phi.shape[2])) #initialize beta at 0. beta is shape tk. movie_seq first dim is t\n",
    "# center = (dim/2)*np.ones((2,movie_length,phi.shape[2])) #shape 2tk (2 since center is 2-vector). initialize centers at center of image. each center is 2-vector\n",
    "# center = center.astype(float)\n",
    "# radius2 = ((dim/2+1)**2)*np.ones((movie_length,phi.shape[2])) # shape tk.initialize radius2 at 17^2, so start off region of interest as entire image\n",
    "# ratius2 = radius2.astype(float)\n",
    "# phi = learnedPhi8NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def InferLocal2NP(movie_seq, phi, sparsePen, derivPen, eta2, eta3, eta4, betaStep, attStep, numInference): \n",
    "#     #now want to infer beta, center, and radii for a single movie sequence\n",
    "#     #***RADII ARE SQUARED, to make computing the derivative easier***\n",
    "#     #assume movie sequence is shape txn2, where t is length (movie_length) and n2 is product of dimensions of 2d image\n",
    "    \n",
    "#     dim = int(np.sqrt(movie_seq.shape[1]))\n",
    "#     Input = movie_seq[:(movie_seq.shape[0]-1)]\n",
    "#     Output = movie_seq[1:]\n",
    "#     Input2 = Input.reshape((Input.shape[0],dim,dim)) #just reshape to make region of interest indices more natural\n",
    "#     movie_length = Input2.shape[0]\n",
    "    \n",
    "#     beta = np.zeros((Input2.shape[0],phi.shape[2])) #initialize beta at 0. beta is shape tk. movie_seq first dim is t\n",
    "#     center = (dim/2)*np.ones((2,movie_length,phi.shape[2])) #shape 2tk (2 since center is 2-vector). initialize centers at center of image. each center is 2-vector\n",
    "#     radius2 = ((dim/2+1)**2)*np.ones((movie_length,phi.shape[2])) # shape tk.initialize radius2 at 17^2, so start off region of interest as entire image\n",
    "    \n",
    "#     for bigStep in range(numInference):\n",
    "#         beta = InferBeta2NP(Input2, center, Output, radius2, phi ,beta, eta, epsilon, betaStep, movie_length, dim)\n",
    "#         radius2 = InferRadius2NP(Input2, center, Output, radius2, phi, beta, eta3, epsilon, attStep, movie_length, dim)\n",
    "#         center = InferCenterNP(Input2, center, Output, radius2, phi, beta, eta4, epsilon, attStep, movie_length, dim)\n",
    "#         print(bigStep, end='\\r')\n",
    "    \n",
    "#     finalImg = localImage(Input2, movie_length, dim, center, radius2, epsilon).reshape((center.shape[2],movie_length, Input.shape[1]))\n",
    "#     final_predictions = np.einsum('tk,ijk,ktj -> ti', beta, phi, finalImg, optimize = True)\n",
    "    \n",
    "#     fig = plt.figure(figsize = (20,6)) #plot the figures, top is ground truth, bottom is predictions\n",
    "#     for i in range(movie_length):\n",
    "#         for j in range(2):\n",
    "#             fig.add_subplot(2,movie_length,movie_length*j+i+1)\n",
    "#             if j == 0:\n",
    "#                 plt.imshow(Output[i].reshape((dim,dim)),cmap = \"Greys\")\n",
    "#             else: \n",
    "#                 plt.imshow(final_predictions[i].reshape((dim,dim)),cmap=\"Greys\")\n",
    "    \n",
    "#     return((beta,radius2,center))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_densNP(x ,epsilon):\n",
    "    z = (1/np.sqrt(2*np.pi*epsilon))*np.exp((-(x**2))/(2*epsilon**2))\n",
    "    return(z)\n",
    "\n",
    "def diffMatNP(movie_length, dim, center, radius2):    \n",
    "    diff_mat = np.empty((2,center.shape[2], movie_length, dim, dim)) #shape 2ktdd\n",
    "    \n",
    "    for k in range(center.shape[2]):\n",
    "        for t in range(movie_length):\n",
    "            for i in range(dim):\n",
    "                for j in range(dim):\n",
    "                    diff_mat[:,k,t,i,j] = (np.array([i,j])-center[:,t,k])\n",
    "\n",
    "                        \n",
    "    return(diff_mat)\n",
    "\n",
    "def localImageNP(Input2, movie_length, dim, center, radius2, epsilon):\n",
    "    local_matrix = np.empty((center.shape[2], movie_length, dim,dim)) #shape is ktdd, where k is number of transforms, t is time, d is dim of image\n",
    "    \n",
    "    for k in range(center.shape[2]):\n",
    "        for t in range(movie_length):\n",
    "            for i in range(dim):\n",
    "                for j in range(dim):\n",
    "                    local_matrix[k,t,i,j] = np.linalg.norm(np.array([i,j])-center[:,t,k])/radius2[t,k]\n",
    "    local_matrix[local_matrix <= 1+ np.sqrt(epsilon)] = 1\n",
    "    local_matrix[local_matrix > 1 + np.sqrt(epsilon)] = 0\n",
    "    \n",
    "    LocalInput2 = np.multiply(local_matrix, Input2)\n",
    "    \n",
    "    return(LocalInput2)\n",
    "\n",
    "def InferNbdNP(Input2, center, Output, radius2, phi, beta, eta3, eta4, epsilon, attStep, movie_length, dim):\n",
    "    for step in range(attStep):\n",
    "        localimg = localImageNP(Input2, movie_length, dim, center, radius2, epsilon).reshape((center.shape[2],movie_length, Input2.shape[1]**2)) #calculate localized images and reshape\n",
    "        \n",
    "        predictions = np.einsum('tk,ijk,ktj -> ti', beta, phi, localimg, optimize = True)\n",
    "        error = Output - squashNP(predictions)\n",
    "        dTanh = squash_derivNP(predictions)\n",
    "        diff = diffMatNP(movie_length, dim, center, radius2)\n",
    "        dist = np.linalg.norm(diff,axis=0)+.01\n",
    "        rad_mat = np.ones_like(dist)\n",
    "        rad_mat = np.multiply(rad_mat,np.expand_dims(np.expand_dims(radius2.T, axis=2), axis = 3)) #array where kt is radius over all ij entries\n",
    "        PD_1 = norm_densNP(dist, epsilon)\n",
    "        PD_2 = norm_densNP(dist-rad_mat, epsilon)\n",
    "        PD_2 = (1/epsilon)*np.multiply(PD_1 - PD_2, diff/dist).reshape((2,center.shape[2],movie_length, Input2.shape[1]**2))                \n",
    "        centerPD = np.multiply(localimg, PD_2)\n",
    "        radPD = (1/epsilon)*np.multiply(localimg, PD_1.reshape(center.shape[2],movie_length, Input2.shape[1]**2)) #radius partial deriv\n",
    "        \n",
    "        \n",
    "        dR = np.einsum('ti, tk, ijk, tj, ktj -> tk', error, beta, phi, dTanh, radPD, optimize= True)\n",
    "        radius2 += eta3*dR\n",
    "        dC = np.einsum('ti, tk, ijk, tj, cktj -> ctk', error, beta, phi, dTanh, centerPD, optimize = True)\n",
    "        center += eta4*dC\n",
    "    return(radius2,center)\n",
    "\n",
    "def InferBeta2NP(Input2, center, Output, radius2, phi ,beta, eta, epsilon, betaStep, movie_length, dim):\n",
    "    \n",
    "    for step in range(betaStep):\n",
    "        \n",
    "        localimg = localImageNP(Input2, Input2.shape[0], dim, center, radius2, epsilon).reshape((center.shape[2],movie_length, Input2.shape[1]**2)) #calculate localized images and reshape\n",
    "        \n",
    "        predictions = np.einsum('tk,ijk,ktj -> ti', beta, phi, localimg, optimize=True)\n",
    "        error = Output - squashNP(predictions)\n",
    "        dTanh = squash_derivNP(predictions)\n",
    "        dBeta = np.einsum('ti,ijk, tj, ktj -> tk', error, phi, dTanh, localimg, optimize=True) - sparsePen*sparseDerivNP(np.expand_dims(beta,axis=0))[0,:,:] - derivPen*timeDerivNP(np.expand_dims(beta,axis=0))[0,:,:]\n",
    "        #just a bit of reshaping magic above to make the functions work, since sparse/derivPen made for data with extra batch dim\n",
    "        beta += eta2*dBeta\n",
    "    \n",
    "    return(beta)\n",
    "\n",
    "def InferLocalNP(movie_seq, phi, sparsePen, derivPen, eta2, eta3, eta4, betaStep, attStep, numInference): \n",
    "    #now want to infer beta, center, and radii for a single movie sequence\n",
    "    #***RADII ARE SQUARED, to make computing the derivative easier***\n",
    "    #assume movie sequence is shape txn2, where t is length (movie_length) and n2 is product of dimensions of 2d image\n",
    "    \n",
    "    dim = int(np.sqrt(movie_seq.shape[1]))\n",
    "    Input = movie_seq[:(movie_seq.shape[0]-1)]\n",
    "    Output = movie_seq[1:]\n",
    "    Input2 = Input.reshape((Input.shape[0],dim,dim)) #just reshape to make region of interest indices more natural\n",
    "    movie_length = Input2.shape[0]\n",
    "    \n",
    "    beta = np.zeros((Input2.shape[0],phi.shape[2])) #initialize beta at 0. beta is shape tk. movie_seq first dim is t\n",
    "    center = (dim/2)*np.ones((2,movie_length,phi.shape[2])) #shape 2tk (2 since center is 2-vector). initialize centers at center of image. each center is 2-vector\n",
    "    radius2 = ((dim/2+1))*np.ones((movie_length,phi.shape[2])) # shape tk.initialize radius2 at 17^2, so start off region of interest as entire image\n",
    "    \n",
    "    for bigStep in range(numInference):\n",
    "        beta1 = InferBeta2NP(Input2, center, Output, radius2, phi ,beta, eta, epsilon, betaStep, movie_length, dim)\n",
    "        radius2, center = InferNbdNP(Input2, center, Output, radius2, phi, beta1, eta3, eta4, epsilon, attStep, movie_length, dim)\n",
    "        print(bigStep, end = '\\r')\n",
    "    \n",
    "    finalImg = localImageNP(Input2, movie_length, dim, center, radius2, epsilon).reshape((center.shape[2],movie_length, Input.shape[1]))\n",
    "    final_predictions = np.einsum('tk,ijk,ktj -> ti', beta, phi, finalImg, optimize = True)\n",
    "    \n",
    "    fig = plt.figure(figsize = (20,6)) #plot the figures, top is ground truth, bottom is predictions\n",
    "    for i in range(movie_length):\n",
    "        for j in range(2):\n",
    "            fig.add_subplot(2,movie_length,movie_length*j+i+1)\n",
    "            if j == 0:\n",
    "                plt.imshow(Output[i].reshape((dim,dim)),cmap = \"Greys\")\n",
    "            else: \n",
    "                plt.imshow(final_predictions[i].reshape((dim,dim)),cmap=\"Greys\")\n",
    "    \n",
    "    return((beta,radius2,center))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infer without attentional window\n",
    "test_raw = test.unsqueeze(0)\n",
    "dim = test_raw.size()[2]     \n",
    "test_rawIn = test_raw[:,:(test_raw.size()[1]-1),:] #will predict next frame from these\n",
    "test_rawOut = test_raw[:,1:,:] #the frames to be predicted\n",
    "learnPhi8_cuda = torch.from_numpy(learnPhi8)\n",
    "learnPhi8_cuda = learnPhi8_cuda.float().cuda()\n",
    "movie_length = test_rawIn.size(1)\n",
    "\n",
    "test_rawBeta = inferBeta(test_rawIn, test_rawOut, learnPhi8_cuda, sparsePen, derivPen, eta2)\n",
    "test_rawPred = torch.einsum('btk,ijk,btj -> bti', test_rawBeta, learnPhi8_cuda, test_rawIn)\n",
    "test_rawPred = test_rawPred.squeeze(0)\n",
    "test_rawPredNP = torch.Tensor.numpy(torch.Tensor.cpu(test_rawPred))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (20,6)) #plot the figures, top is ground truth, bottom is predictions\n",
    "for i in range(movie_length):\n",
    "    for j in range(2):\n",
    "        fig.add_subplot(2,movie_length,movie_length*j+i+1)\n",
    "        if j == 0:\n",
    "            plt.imshow(testNP[19,i+1].reshape((16,16)),cmap = \"Greys\")\n",
    "        else: \n",
    "            plt.imshow(test_rawPredNP[i].reshape((16,16)),cmap=\"Greys\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this run was for 100 total cycles, 10/10 per center/radius. learning center/rad were .1/.2. Epsilon set to 1. \n",
    "#Also, I changed local image threshold from 1+epsilon to be 1+sqrt(epsilon).\n",
    "testrun6 = InferLocalNP(testNP[19], learnPhi8, sparsePen, derivPen, eta2, eta3, eta4, betaStep, attStep, numInf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this run was for 100 total cycles, 10/10 per center/radius. learning center/rad were .5/.5. Epsilon set to 1. \n",
    "#Also, I changed local image threshold from 1+epsilon to be 1+sqrt(epsilon).\n",
    "testrun5 = InferLocalNP(testNP[19], learnPhi8, sparsePen, derivPen, eta2, eta3, eta4, betaStep, attStep, numInf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this run was for 100 total cycles, 20/10 per center/radius. learning center/rad were .5/.5. Epsilon set to 1. \n",
    "#Also, I changed local image threshold from 1+epsilon to be 1+sqrt(epsilon).\n",
    "testrun = InferLocalNP(testNP[19], learnPhi8, sparsePen, derivPen, eta2, eta3, eta4, betaStep, attStep, numInf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infer without attentional window\n",
    "datanum = 4\n",
    "test_raw = test[datanum].unsqueeze(0)\n",
    "dim = test_raw.size()[2]     \n",
    "test_rawIn = test_raw[:,:(test_raw.size()[1]-1),:] #will predict next frame from these\n",
    "test_rawOut = test_raw[:,1:,:] #the frames to be predicted\n",
    "learnPhi8_cuda = torch.from_numpy(learnPhi8)\n",
    "learnPhi8_cuda = learnPhi8_cuda.float().cuda()\n",
    "movie_length = test_rawIn.size(1)\n",
    "\n",
    "test_rawBeta = inferBeta(test_rawIn, test_rawOut, learnPhi8_cuda, sparsePen, derivPen, eta2)\n",
    "test_rawPred = torch.einsum('btk,ijk,btj -> bti', test_rawBeta, learnPhi8_cuda, test_rawIn)\n",
    "test_rawPred = test_rawPred.squeeze(0)\n",
    "test_rawPredNP = torch.Tensor.numpy(torch.Tensor.cpu(test_rawPred))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (20,6)) #plot the figures, top is ground truth, bottom is predictions\n",
    "for i in range(movie_length):\n",
    "    for j in range(2):\n",
    "        fig.add_subplot(2,movie_length,movie_length*j+i+1)\n",
    "        if j == 0:\n",
    "            plt.imshow(testNP[datanum,i+1].reshape((16,16)),cmap = \"Greys\")\n",
    "        else: \n",
    "            plt.imshow(test_rawPredNP[i].reshape((16,16)),cmap=\"Greys\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this run was for 100 total cycles, 20/10 per center/radius. learning center/rad were .1/.2. Epsilon set to .8. \n",
    "#Also, I changed local image threshold from 1+epsilon to be 1+sqrt(epsilon).\n",
    "testrun = InferLocalNP(testNP[4], learnPhi8, sparsePen, derivPen, eta2, eta3, eta4, betaStep, attStep, numInf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this run was for 100 total cycles, 10/10 per center/radius. learning center/rad were .5/5. Epsilon set to 1. \n",
    "frame = 4\n",
    "fig_testrun2 = plt.figure(figsize=(15,7)) #image sequence from dataset\n",
    "ax1 = fig_testrun2.add_subplot(1,3,1)\n",
    "ax1.bar(list(range(16)), (testrun2[0])[frame,:])\n",
    "ax1.title.set_text('Transform Coeffs')\n",
    "ax2 = fig_testrun2.add_subplot(1,3,2)\n",
    "ax2.bar(list(range(16)), (testrun2[1])[frame,:])\n",
    "ax2.title.set_text('Radius per Transform')\n",
    "ax3 = fig_testrun2.add_subplot(1,3,3)\n",
    "ax3.scatter((testrun2[2])[0,0,:],(testrun2[2])[1,frame,:])\n",
    "ax3.title.set_text('Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this run was for 100 total cycles, 15/15 per center/radius. learning center/rad were 2/5. Epsilon set to 1.5 \n",
    "#Also, I changed local image threshold from 1+epsilon to be 1+sqrt(epsilon).\n",
    "frame = 3\n",
    "fig_testrun3 = plt.figure(figsize=(15,7)) #image sequence from dataset\n",
    "ax1 = fig_testrun3.add_subplot(1,3,1)\n",
    "ax1.bar(list(range(16)), (testrun3[0])[frame,:])\n",
    "ax1.title.set_text('Transform Coeffs')\n",
    "ax2 = fig_testrun3.add_subplot(1,3,2)\n",
    "ax2.bar(list(range(16)), (testrun3[1])[frame,:])\n",
    "ax2.title.set_text('Radius per Transform')\n",
    "ax3 = fig_testrun3.add_subplot(1,3,3)\n",
    "ax3.scatter((testrun3[2])[0,0,:],(testrun3[2])[1,frame,:])\n",
    "ax3.title.set_text('Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this run was for 100 total cycles, 10/10 per center/radius. learning center/rad were .5/.5. Epsilon set to 1. \n",
    "#Also, I changed local image threshold from 1+epsilon to be 1+sqrt(epsilon).\n",
    "frame = 2\n",
    "fig_testrun5 = plt.figure(figsize=(15,7)) #image sequence from dataset\n",
    "ax1 = fig_testrun5.add_subplot(1,3,1)\n",
    "ax1.bar(list(range(16)), (testrun5[0])[frame,:])\n",
    "ax1.title.set_text('Transform Coeffs')\n",
    "ax2 = fig_testrun5.add_subplot(1,3,2)\n",
    "ax2.bar(list(range(16)), (testrun5[1])[frame,:])\n",
    "ax2.title.set_text('Radius per Transform')\n",
    "ax3 = fig_testrun5.add_subplot(1,3,3)\n",
    "ax3.scatter((testrun5[2])[0,0,:],(testrun5[2])[1,frame,:])\n",
    "ax3.title.set_text('Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
